# Kafka 面试

## 生产者发送消息模式

1. **发后即忘**（fire-and-forget）
   不关心消息是否正确到达。效率高，可靠性差
2. **同步**（sync）
   send() 返回一个Future对象，调用get()进行同步等待，进而判断消息是否发送成功
   发送一条消息需要等上个消息发送成功后才可以继续发送
3. **异步**（async）
   send() 传入一个回调函数，消息不管成功或者失败都会调用这个回调函数



## Kafka可靠性保证

1. Producer ---- acks

   * acks = 0
     发送完就完了，不需要等待响应
     特点：只要服务端写消息时出现任何问题，都会导致消息丢失
   * acks = 1  默认
     只要 leader 副本成功写入消息，就代表成功
     特点： leader 副本和 follower 副本还没有来得及同步，leader 就崩溃了，消息丢失
   * acks = -1 或 acks = all
     等待 ISR 中的所有副本都成功写
     特点：可靠性是最高，性能最差

2. Producer ---- 失败重试

   同步和异步获取响应结果，进行失败重试

3. Consumer ---- 手动提交位移
   默认：自动提交
   开启手动提交offsets，消费成功再提交offsets

## 消息重复消费（幂等性）

1. Producer ---- 重复发消息
   Producer有重试机制，网络抖动导致发送超时，Producer再次发送
2. Consumer
   Consumer拉取了一批数据，还没来得及提交offsets就挂了，下次重启又重新拉取

解决方案：Consumer做幂等性

## 消息乱序

1. Consumer开启了重试机制，kafka不会等消费成功才发送下一条数据
   例如：consumer收到消息：1、2、3........，1消费失败了，但是2、3成功了.此时1重试。对于consumer来说收到消息顺序：2、3、1

## 消息堆积

1. Producer生产消息太快，Consumer消费太慢
   解决方案：多分区，让多个consumer来消费
2. Consumer异常，一直消费失败
   如果一直失败将消息转到死信队列，后续研究解决

## 延迟队列

1. 将消息分别发送到不同的队列（topic_1s，topic_2s，topic_5s），定时器轮询消费这些topic，看是否过期，如果过期则转移消息到业务topic

## 分区数越多，性能不一样越好

1. 客户端/服务器端需要使用的内存就越多
   服务端：服务器维护了分区级别的缓存，分区数越大，缓存成本越大
   生产者：发送消息时会为每个分区缓存消息，当积累到一定程度之后再发送到broker，分区越多，所需缓存越大
   消费者：消费者线程数跟分区数挂钩，分区数越大，消费的线程数越多
2. 文件句柄开销
   每个partition对应磁盘文件系统的一个目录，分区越多，所需要保持打开状态的文件句柄数也就越多（操作系统配置的文件句柄数量限制）
3. 分区越多增加端对端的延迟（可能）
   分区越多，partition越多，副本间同步后HW才会修改（前提：acks = -1 或 acks = all），延迟
4. 降低高可用性
   Reblance机制，分区数越多，恢复所需时间越长
   新的 controlle，从 zookeepe获取 partition 的元数据信息用于初始化数据

## Kafka为什么快

1. 顺序读写
2. Page Cache
   利用操作系统自身的内存而不是JVM空间内存
3. 零拷贝
   数据从内核空间的读缓冲区直接拷贝到内核空间的 socket 缓冲区
4. 分区分段 + 索引
5. 批量读写消息
   避免在网络上频繁传输单个消息带来的延迟和带宽开销
6. 批量压缩

## **ZooKeeper的作用**

1. 存放元数据
   topic、partition等数据存放在Zookeeper
2.  Broker 节点的注册、注销以及属性变更
3. Controller选举

url：https://www.163.com/dy/article/GEG5JDJD0552C1II.html

