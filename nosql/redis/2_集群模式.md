# Redis集群模式

## 主从模式

```mermaid
graph TB
A("Master 写")-->B1("Slave1 读")
A-->B2("Slave2 读")
```

## 流程

客户端连接Master, Master分配操作

1. 写：Master写入数据并同步到Slave
2. 读：Master将读命令分配给Salve

### 优缺点

1. 优点： 读写分离，效率高；数据热备份

2. 缺点：Master节点宕机，无法自动选举新的Master

   ​           Master只有一个，写命令存在性能瓶颈

   ​           全量同步存在卡顿(秒级、或者毫秒级)

## psync 命令 

### Slave发送的命令

1. slave从未发起同步或SLAVEOF no one命令，同步命令：PSYNC ? -1

2. Slave有曾经从Master获取过数据，同步命令：psync runid offset

3. Master收到以上两个请求，响应参数：

   ```shell
   +FULLRESYNC <runid> <offset>：将进行全量同步，runid为Master节点id,Slave将其保存下来，下次发起同步请求需要用到
   +CONTINUE： 将进行增量同步
   -ERR： 版本错误，无法识别PSYNC命令
   ```

### 参数说明

1. offset复制偏移量(查看: info replication)
   Master的offset: 
   Slave的offet:  从库已同步的字节数

2. replication backlog buffer（复制积压缓冲区）

   所有Salve共用一份
   FIFO队列，大小由配置参数repl-backlog-size指定，默认大小1MB。所以只能存储最近的命令（包含offset和每个offset对应的命令）

3.  run_id(服务器运行的唯一ID)(查看: info server)
   每个redis实例启动时，都会生成一个长度为40的唯一字符串
   注意点：版本 < Redis4.0; redis重启时，runid会变，导致全量同步

### Master处理Psync命令流程

![2_psync](D:\project\huan415\http\JavaYang\nosql\redis\images\2_psync.jpg)

### 全量复制(PSYNC ? -1)

时机：Slave第一次连接Master或者Slave宕机太久后重启（offset不在repl_back_buffer）

```sequence
title: redis主从复制之全量同步
participant Slave
Participant Master

Slave->Master: 0:建立socket长连接
Slave->Master: 1:psync第一次同步请求
Master->Master: 2:收到psync命令，bgsave生成RDB快照
Master->Master: 3:生成快照期间或者之后的写命令放入repl_back_buffer
Master-->Slave: 4:发送RDB快照
Slave->Slave: 5:flush old data
Master-->Slave: 6:send buffer 发送bgsave之后的命令
Slave->Slave: 7:将buffer也加载到RDB中和内存中
Master-->Slave: 8:Socket长连接时时向Slave同步数据


```



## 增量同步 (psync runid offset)

增量同步时，对比runid和offset

1. runid不一样：说明进行过Master切换了，需要进行全量同步
2. offet不在repl_back_buffer: 说明宕机太久了，需要进行一次全量同步

```sequence
title: redis主从复制之增量同步
participant Slave
Participant Master

Slave->Master: 0:连接断开
Master->Master: 1: Master时时将最新执行的命令写入repl_back_buffer
Slave->Master: 2:重新建立socket连接
Slave->Master: 3:psync runid offset
Master->Master: 4:判断offet是否在repl_back_buffer中,如果不在则进行全量同步，详见上图，否则进行下一步增量同步
Master-->Slave: 将offet之后的数据一次性发送给Slave
Master-->Slave: Socket长连接时时向Slave同步数据
```



## todo Redis4.0 p3sync命令区别



## 哨兵模式

### 概念

如上诉可知，主从模式下，只起到读写分离和备份的作用，当Master宕机时，无法重新选举（Slave无法成为新的Master）,需要人工介入。这样在生产环境下不可靠，于是诞生了哨兵模式，监控各个节点，当Master挂了之后，Slave间被选举成为新的Master。

sentinel哨兵的特殊的redis服务，它不提供读写访问，主要功能：监控redis实例节点

如下图所示：clientId并不是直接连Master节点，而是连哨兵集群，及时获取可用Master节点ip；哨兵集群监控redis主从（Master和Slave）,当Master宕机之后，进行选举并返回新的Master ip给client。在选举期间会造成短暂性无法访问。

![2_sentinel](https://github.com/huan415/JavaYang/blob/master/nosql/redis/images/2_sentinel.jpg)

### 选举

Master挂掉之后，先选举领头哨兵(Sentinel leader)，由它负责故障转移，从Slave里选出Master

#### 领头哨兵的选举(Sentinel协商选举)

1. 哨兵A发现master下线，会向其它哨兵发现命令：选举自己为领头哨兵
2. 其他哨兵如果未选举其他人，则同意A成为领头哨兵
3. 如果A选票过半，则A当选未领头哨兵
4. 如果多个哨兵竞争，且没有一个哨兵选票过半，则此轮选举失败，开始下一轮的选举

#### Master的选举(由第三方--Sentinel leader选举)

1. 领导哨兵对比slave-priority，选择优先级高的
2. 领导哨兵对比offset(复制偏移量最大)，选择大的，复制偏移量最大越大，数据余越完整，
3. 领导哨兵对比runid，选择id小的
4. 领导哨兵向redis发送命令，升级slave1为新的Master,
   领导哨兵向其他slave发送命令，接收slave1为新的Master,
   领导哨兵更新配置文件,新的Master更新成主库，旧的Master更新为从库(重启后就是从库)

## Cluster集群模式

### 概念

如上所述，哨兵模式有如下不足

1. 选举时，造成一段时间内redis不可用（访问瞬断）
2. 只有一个Master可以写数据，Master存在瓶颈
3. 当redis需要存储大量数据时，每个节点都r有很大的RDB和AOF文件，宕机重启时，回复数据很慢

于是出现了新的集群模式，如下图所示：

n个主从模式组合成集群模式，每个主从模式都是独立的，共16384个槽位，分配给每个主从模式，即：每个主从模式相互独立，存储不同的数据，实现水平扩展。

知识点：

1. redis集群至少需要三个主从，即至少三个Master
2. 客户端存储各个几点ip和槽位
3. 槽位算法：HASH_SLOT = CRC16(key) mod 16384
4. 跳转重定位：client给A节点的Master发生命令，A节点发现这个槽位不是自己的范围内，会告诉客户端正确的节点ip，client跳转重定向到正确的节点执行命令，并刷新client的槽位缓存表
5. redis cluster节点间采用gossip协议进行通信：ping、pong、meet、fail
6. 网络抖动：cluster­node­timeout 允许节点失联的最长时间

![2_sentinel](https://raw.githubusercontent.com/huan415/JavaYang/master/assets/2_sentinel.jpg)

### Cluster选举

1. Slave发现自己的master变为fail
2. Slave将currentEpoch加1，并广播FAILOVER_AUTH_REQUEST（通知所有节点选举自己为Master）
3. 所有节点都收到了，但是只有Master会进行响应，返回FAILOVER_AUTH_ACK，同一个epoch只发送一次
4. Slave手机FAILOVER_AUTH_ACK，超过半数当选Master
5. 新的Master广播其他集群节点

注意：Salve得知Master节点Fail之后延迟一定时间再进入选举，并不会马上选举，为了确保其他节点感应到Master处于Fail状态
延迟时间： DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms

### 为什么Master至少是三个，且最好是奇数个

1. 因为Master的选举需要得到至少半数以上的票数，如果是两个，那么挂掉其中一个，将无法进行新Master的选举
2. 为了满足选举条件的基础之上节省集群资源。例如：3个Master和4个Master对于选举的效果是一样的：
   当挂掉1个Master,剩下2、3个Master都可以完成选举(3的半数以上：2，4的半数以上：3)
   当挂掉2个Master,剩下1、2个Master都不可以完成选举(3的半数以上：2，4的半数以上：3)

### Cluster命令

```shell
1. 帮助命令
   ./redis‐cli ‐‐cluster help
2. 为集群新加节点(新增的节点没有槽位,要手动分配槽位)
   其中masterauth：集群节点间访问所需的密码；
   ip1:port1：新节点的ip和port;
   ip1:port1：集群里任意节点的ip和port
   ./redis‐cli ‐a masterauth ‐‐cluster add‐node ip1:port1 ip2:port2
3. 查看集群状态
   ./redis‐cli ‐a masterauth ‐c ‐h ip ‐p port(进入节点)
   cluster nodes
4. reshard手动分配槽位
    ./redis‐cli ‐a masterauth ‐‐cluster reshard ip:port
5. replicate将当前slave节点指定到一个主节点下，runid为Master的节点id
   ./redis‐cli ‐a masterauth ‐c ‐h ip ‐p port(进入节点)
   cluster replicate runid
6. del‐node删除节点，Master节点：先移除槽位，再删除节点。Slave节点：直接删除节点
   ./redis‐cli ‐a masterauth ‐‐cluster reshard ip:port
   ./redis‐cli ‐a masterauth ‐‐cluster del‐node ip:port runid
```

