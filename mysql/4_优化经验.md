# 优化经验

## 索引最左前缀原则

```mysql
CREATE TABLE `huan415_explain`  (
  `id` bigint(20) NOT NULL,
  `f1` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f2` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f3` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f4` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `idx_f1_f2_f3`(`f1`, `f2`, `f3`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

INSERT INTO `yangyc`.`huan415_explain`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (1, 'a', 'a', 'a', 'a');
INSERT INTO `yangyc`.`huan415_explain`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (2, 'b', 'b', 'b', 'b');

```



```sql
#以下三个都会走联合索引
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1='a';                         #左           key_len=33
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1='a' AND f2='a';              #f1，f2       key_len=66
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1='a' AND f2='a' AND f3='a';   #f1，f2，f3   key_len=99

#以下三个都不会走索引，因为少了最左边的f1
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f2='a';
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f3='a';
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f2='a' AND f3='a';

#以下一个会走联合索引，索引生效字段：f1，因为少了中间的f1,相当于“线索中断”了，f3走不了索引
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1='a' AND f3='a';               #f1         key_len=33
 
#以下两个个都会走联合索引，索引生效字段：f1，f2，因为不等号使得f2只能确定范围，无法确定具体的索引树值，使得后面的f3无法走索引
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1='a' AND f2>'a' AND f3='a';     #f1，f2     key_len=66
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1='a' AND f2<'a' AND f3='a';     #f1，f2     key_len=66
#以下两个个都会走联合索引，索引生效字段：f1，f2，f3，不能简单的看等于号右边，要看联合索引的字段顺序，因为优化器的优化会把f2和f3顺序对换
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1='a' AND f3>'a' AND f2='a';     #f1，f2，f3   key_len=99
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1='a' AND f3<'a' AND f2='a';     #f1，f2，f3   key_len=99

#以下第一条走索引，第二条不走索引，原因：优化器优化，查询范围太大，倒不如走全表扫描快
#优化思路：缩小收索范围
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 > 'a' and f1 < 'b';            #f1         key_len=33
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 > '1' and f1 < 'zzzzzzzz';     #全表扫描

#第一个走索引，第二个不走索引，结合索引树，从左边开始一个值一个值地比较，左边能确定值时可以确定位置，左边不能确定值（模糊）时不能确定位置
#优化方式：使用覆盖索引，不用回表查
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 like 'a%';                      #f1         key_len=33
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 like '%a';

#以下两个都不走索引，因为不等于在索引树中就只有一个能满足条件，大部分不满足条件，倒不如全表扫描比较快
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1!='a';
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1<>'a';

# is null、is not null可能走索引，可能不走索引，取决于优化器计算出的成本
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 is null;                         #f1         key_len=33
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 is not null;                     #f1         key_len=33
# 以下同样的sql就不走索引了，在原来的数据基础之上再加上几条null值的之后，就不走索引了
INSERT INTO `yangyc`.`huan415_explain`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (3, NULL, NULL, NULL, NULL);
INSERT INTO `yangyc`.`huan415_explain`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (4, NULL, NULL, NULL, NULL);
INSERT INTO `yangyc`.`huan415_explain`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (5, NULL, NULL, NULL, NULL);
INSERT INTO `yangyc`.`huan415_explain`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (6, '6', NULL, NULL, NULL);
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 is null;
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 is not null;

#覆盖索引、查询列都被索引覆盖
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f2='a' AND f3='a';                    #Using where 
EXPLAIN SELECT f1,f2,f3 FROM `yangyc`.`huan415_explain` WHERE f1='a' AND f2='a' AND f3='a';  #Using index

#函数、类型转换不会走索引，变成全表扫描
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE LEFT(f1,2) = 'a';                     #mysql机制：一旦使用函数就不走索引
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1=1;                                 #类型不匹配，隐式类型转换，不走索引
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1='a';                               #f1         key_len=33

#in、or不一定不走索引，主要取决于in里面的个数
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 in('a');                           #f1         key_len=33
EXPLAIN SELECT * FROM `yangyc`.`huan415_explain` WHERE f1 in('a','a1','a2','a3','a4');       #全表扫描

```



## 分页问题

```mysql
CREATE TABLE `huan415_explain`  (
  `id` bigint(20) NOT NULL,
  `f1` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f2` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f3` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f4` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `idx_f1_f2_f3`(`f1`, `f2`, `f3`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;


CREATE DEFINER=`skip-grants user`@`skip-grants host` PROCEDURE `generateData`(IN in_start INT(10),IN in_end INT(10))
BEGIN 
 SET autocommit = 0;    
 REPEAT  
 SET in_start = in_start + 1;  
 INSERT INTO `yangyc`.`huan415_explain` (f1,f2,f3,f4) VALUES (concat("f1",in_start),concat("f2",in_start),concat("f3",in_start),concat("f4",in_start));  
 UNTIL in_start = in_end  
 END REPEAT;  
 COMMIT;  
 END
 
# 生成数据
call generateData(1,10000);


# 分页问题, 越往后，查询效率越低。因为mysql先读取99990，在读接下来10
SELECT * FROM  `yangyc`.`huan415_explain` limit 0,10;             # 耗时：0.043
SELECT * FROM  `yangyc`.`huan415_explain` limit 99990,10;         # 耗时：0.116   Using filesort

#第一条走索引，第二条不走索引。因为第二条分页的数据很靠后，需要先把前面的数据先查出来，mysql优化器认为先查联合索引，再回表查数据，查多个索引树的成本比全表扫描高，故放弃索引走全表扫描
EXPLAIN SELECT * FROM  `yangyc`.`huan415_explain` ORDER BY f1 limit 0,10;
EXPLAIN SELECT * FROM  `yangyc`.`huan415_explain` ORDER BY f1 limit 99990,10;

# 优化思路1： 主键连续且自增时
SELECT * FROM  `yangyc`.`huan415_explain` WHERE id > 99990 limit 10;

# 优化思路2： 主键不连续时, 小表驱动大表，小表覆盖索引且返回的数据尽可能的少
SELECT a.* FROM `yangyc`.`huan415_explain` a inner join (SELECT id FROM  `yangyc`.`huan415_explain` ORDER BY f1 limit 99990,10) b on a.id = b.id;                                                  # 耗时：0.091     Using index


```





# JOIN 的原理

```mysql
CREATE DEFINER=`skip-grants user`@`skip-grants host` PROCEDURE `generateData`(IN in_start INT(10),IN in_end INT(10))
BEGIN 
 SET autocommit = 0;    
 REPEAT  
 SET in_start = in_start + 1;  
 INSERT INTO `yangyc`.`huan415_join1` (f1,f2,f3,f4) VALUES (concat("f1",in_start),concat("f2",in_start),concat("f3",in_start),concat("f4",in_start));  
 UNTIL in_start = in_end  
 END REPEAT;  
 COMMIT;  
 END

CREATE TABLE `huan415_join1`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `f1` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f2` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f3` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f4` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `idx_f1`(`f1`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10000 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

# 大表，生成100000条数据
call generateData(1,100000);

CREATE TABLE `huan415_join2`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `f1` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f2` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f3` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f4` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `idx_f1`(`f1`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10000 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;


# 小表，将上传存储过程表名huan415_join1改成huan415_join2
call generateData(1,10);


# JOIN 按on后面的条件分为两种情况，Extra
# 1. on条件有索引     嵌套循环连接算法（NLJ: Nested-Loop Join Algorithms）
#   原理: 1.扫描驱动表b  2.每扫到一条数据，拿关联字段查a表的索引树  3.合并结果并返回.
#   其中：第一步扫描出10行数据，第二步：根据第一步结果扫描a表索引，共扫描10次索引  
#   整个过程共扫描20行
EXPLAIN SELECT * FROM `yangyc`.`huan415_join1` a INNER JOIN `yangyc`.`huan415_join1` b on a.f1 = b.f1;     #Using where 
# 2. on条件没有索引   块嵌套循环连接算（BNL: Block Nested-Loop Join Algorithm）
#    原理： 1. a表、b表全查   2.b表放入join_buffer   3.a表每一行与join_buffer对比（内存操作）
#    其中：两次全表扫描：100000行+10行，接下来第三步对比是基于内存（100000行*10次），可以忽略，   内存扫描比磁盘扫描快非常多
EXPLAIN SELECT * FROM `yangyc`.`huan415_join1` a INNER JOIN `yangyc`.`huan415_join1` b on a.f2 = b.f2;   #Using where; Using join buffer (Block Nested Loop)

# 对比：NLJ算法有索引树，BNL算法没有索引树，有索引树时利用索引树比较快‘
# 都采用NLJ算法? on后面如果没有索引，即没有索引树，如果要用NLJ算法，只能扫描表，扫描函数10*10000，性能远不如BNL算法，只能退而求其次用BNL算法。
# 都采用BNL算法? on后面有索引树时，采用NLJ算法扫描函数会比较少，性能比较快。
# 总结：on后面有索引树时，用NLJ算法。  没有索引树时用BNL算法

```



## count性能对比

```mysql
count(1)>count(f1)约等于count(*)>count(id)

count(f1): 查辅助索引， 没有所有字段，性能比count(id)快，  缺点：不会统计null值（在索引树中，null值最小，排最前面）
count(*)： 不会查所有字段，优化器进行优化---查辅助索引，且不会忽略null
count(id): 主键树，叶子节点有所有字段，统计慢
```



## mysql 优化器

```mysql
CREATE TABLE `huan415_join1_optimize`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `f1` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f2` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f3` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `f4` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
   INDEX `idx_f1_f2_f3`(`f1`, `f2`, `f3`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

INSERT INTO `yangyc`.`huan415_join1_optimize`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (1, 'a', 'a', 'a', 'a');
INSERT INTO `yangyc`.`huan415_join1_optimize`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (2, 'b', 'b', 'b', 'b');
INSERT INTO `yangyc`.`huan415_join1_optimize`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (3, 'c', 'c', 'c', 'c');
INSERT INTO `yangyc`.`huan415_join1_optimize`(`id`, `f1`, `f2`, `f3`, `f4`) VALUES (4, 'd', 'd', 'd', 'd');

# 查询条件不同，走的索引可能不同（同样的sql,同样多是数据，同一张表）
EXPLAIN SELECT * FROM `yangyc`.`huan415_join1_optimize` WHERE f1 > 'a';#不走索引，查出数据多，查索引树+回表 的成本>全表扫描，优化器进行了优化
EXPLAIN SELECT * FROM `yangyc`.`huan415_join1_optimize` WHERE f1 > 'd';#f1  key_len=33

# 优化思路： 改为覆盖索引
EXPLAIN SELECT f1,f2,f3 FROM `yangyc`.`huan415_join1_optimize` WHERE f1 > 'a';
```



## mysql 排序的两种方式：Using index 和 Using filesort

```mysql
# USing index： 索引树上完成排序，性能高                   Using filesort： 磁盘排序，性能低
# USing index 使用情况： 1.order by符合最左前缀原则     2.where + order by符合最左前缀原则
# Using filesort 使用情况：order by的列不在索引树上
# 类比group by,   group by是先排序后分组，索引也要符合最左前缀原则（order by null可以禁止排序）
#                能用where 不用having（where性能比having好）


# Using filesort原理：
# 1. 单路排序
#    查出所有满足条件的数据（所有字段），然后放在sort_buffer中排序    tarce关键字: sort_key,additional
# 2. 双路排序(回表排序)
#    查出满足条件的排序字段和能定位数据的行id,然后放在sort_buffer排序，再回表查所需字段         trace关键字：sort_key,rowid
# 例如：EXPLAIN SELECT * FROM `yangyc`.`huan415_join1_optimize` WHERE f2  ='a' ORDER BY f3;
#    单路排序：1. 查询一条满足条件f2='a'数据的id   2.拿id回表查所有字段，放入sort_buffer   3.循环1、2直到结束    4.在sort_buffer排序并返回结果
#    双路排序：1. 查询一条满足条件f2='a'数据的id   2.拿id回表查排序字段和主键id,放入放入sort_buffer  3.循环1、2直到结束    4.在sort_buffer排序
#            5. 排好序后按id回表查所需字段并返回
# 对比：两个差别主要是sort_buffer放的数据，单路排序放所有字段，少一次回表查询,性能好点； 但是当数据量大时sort_buffer放不下，只能用双路排序，放某些所需字# #      段，再回表查
#      max_length_for_sort_data来控制buffer_sort大小，默认1M
```

